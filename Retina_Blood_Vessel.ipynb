{"cells":[{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-07-14T10:26:36.300860Z","iopub.status.busy":"2024-07-14T10:26:36.299559Z","iopub.status.idle":"2024-07-14T10:26:38.287840Z","shell.execute_reply":"2024-07-14T10:26:38.286643Z","shell.execute_reply.started":"2024-07-14T10:26:36.300803Z"},"trusted":true},"outputs":[],"source":["import torch\n","from model import UNet\n","from dataset import RetinaDataset\n","from utils import load_data\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2 as cv\n","import json\n","import segmentation_models_pytorch as smp"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 512, 512]) torch.Size([1, 512, 512])\n"]}],"source":["train_images, train_masks, test_images, test_masks = load_data(\"/scratch/y.aboelwafa/Retina_Blood_Vessel_Segmentation/dataset\")\n","train_dataset = RetinaDataset(train_images, train_masks, augment=True)\n","test_dataset = RetinaDataset(test_images, test_masks)\n","X, y = train_dataset[0]\n","print(X.shape, y.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of images in the first batch: torch.Size([4, 3, 512, 512])\n","Shape of labels in the first batch: torch.Size([4, 1, 512, 512])\n"]}],"source":["train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n","\n","first_batch_images, first_batch_labels = next(iter(train_dataloader))\n","print(f\"Shape of images in the first batch: {first_batch_images.shape}\")\n","print(f\"Shape of labels in the first batch: {first_batch_labels.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["BATCH_SIZE = 4\n","EPOCHS = 5\n","LR = 1e-4\n","IN_CHANNELS = 3\n","OUT_CHANNELS = 1\n","CHECKPOINT_PATH = \"/scratch/y.aboelwafa/Retina_Blood_Vessel_Segmentation/checkpoints/checkpoint.pth\"\n","METRICS_PATH = \"/scratch/y.aboelwafa/Retina_Blood_Vessel_Segmentation/metrics/metrics.json\"\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = UNet(in_channels=IN_CHANNELS, out_channels=OUT_CHANNELS).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","criterion = smp.losses.DiceLoss(mode='binary')\n","\n","metrics = {\n","    'train_loss': [], 'val_loss': [],\n","    'train_iou_score': [], 'val_iou_score': [],\n","    'train_dice_score': [], 'val_dice_score': []\n","}\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    for batch_idx, (image, mask) in enumerate(train_dataloader):\n","        image = image.to(device=device)\n","        mask = mask.to(device=device)\n","        optimizer.zero_grad()\n","        pred = model(image)\n","        loss = criterion(pred, mask)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 5 == 0:\n","            print(f\"Epoch {epoch}, batch {batch_idx}, loss: {loss.item()}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for image, mask in test_dataloader:\n","            image = image.to(device=device)\n","            mask = mask.float().to(device=device)\n","            pred = model(image)\n","            loss = criterion(pred, mask)\n","            print(f\"Validation loss: {loss.item()}\")\n","            \n","            \n","with open(METRICS_PATH, 'w') as f:\n","    json.dump(metrics, f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# num_images = 5\n","# fig, axs = plt.subplots(num_images, 2, figsize=(10, 5*num_images))\n","\n","# for i in range(num_images):\n","#     image_tensor, mask_tensor = train_dataset[i]\n","    \n","#     # Convert the image tensor from CxHxW to HxWxC for plotting\n","#     image = image_tensor.numpy().transpose(1, 2, 0)\n","#     mask = mask_tensor.numpy().squeeze()  # Remove the channel dimension from the mask\n","    \n","#     axs[i, 0].imshow(image)\n","#     axs[i, 0].axis('off')\n","#     axs[i, 0].set_title(f'Image {i+1}')\n","    \n","#     axs[i, 1].imshow(mask, cmap='gray')\n","#     axs[i, 1].axis('off')\n","#     axs[i, 1].set_title(f'Mask {i+1}')\n","\n","# plt.tight_layout()\n","# plt.show()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3636171,"sourceId":6318833,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
